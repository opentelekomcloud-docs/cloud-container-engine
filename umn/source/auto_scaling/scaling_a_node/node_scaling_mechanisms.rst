:original_name: cce_10_0296.html

.. _cce_10_0296:

Node Scaling Mechanisms
=======================

HPA is designed for pod-level scaling and can dynamically adjust the number of replicas based on workload metrics. However, if cluster resources are insufficient and new replicas cannot run, you can only scale out the cluster.

`autoscaler <https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler>`__ is an auto scaling component provided by Kubernetes. It automatically scales in or out nodes in a cluster based on the pod scheduling status and resource usage. It supports multiple scaling modes, such as multi-AZ, multi-pod-specifications, metric triggering, and periodic triggering, to meet the requirements of different node scaling scenarios.

Prerequisites
-------------

Before using the node scaling function, you must install the :ref:`autoscaler <cce_10_0154>` add-on of v1.13.8 or later.

How autoscaler Works
--------------------

autoscaler goes through two processes.

-  Scale-out: autoscaler checks all unscheduled pods every 10 seconds and selects a node pool that meets the requirements for scale-out based on the policy you set.

   .. note::

      When autoscaler checks unscheduled pods for scale outs, it uses the scheduling algorithm consistent with the Kubernetes community version for simulated scheduling calculation. If non-built-in kube-schedulers or other non-Kubernetes community scheduling policies are used for application scheduling, when autoscaler is used to expand the capacity for such applications, the capacity may fail to be expanded or may be expanded more than expected due to inconsistent scheduling algorithms.

-  Scale-in: autoscaler scans all nodes every 10 seconds. If the number of pod requests on a node is less than the user-defined percentage for scale-in, autoscaler simulates whether the pods on the node can be migrated to other nodes. If yes, the node will be removed after an idle time window.

   When a cluster node is idle for a period of time (10 minutes by default), cluster scale-in is triggered, and the node is automatically deleted. However, a node cannot be deleted from a cluster if the following pods exist:

   -  Pods that do not meet specific requirements set in Pod Disruption Budgets (`PodDisruptionBudget <https://kubernetes.io/docs/tasks/run-application/configure-pdb/>`__)
   -  Pods that cannot be scheduled to other nodes due to constraints such as affinity and anti-affinity policies
   -  Pods that have the **cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'** annotation
   -  Pods (except those created by DaemonSets in the kube-system namespace) that exist in the kube-system namespace on the node
   -  Pods that are not created by the controller (Deployment/ReplicaSet/job/StatefulSet)

   .. note::

      When a node meets the scale-in conditions, autoscaler adds the **DeletionCandidateOfClusterAutoscaler** taint to the node in advance to prevent pods from being scheduled to the node. After the autoscaler add-on is uninstalled, if the taint still exists on the node, manually delete it.

autoscaler Architecture
-----------------------

:ref:`Figure 1 <cce_10_0296__fig114831750115719>` shows the autoscaler architecture and its core modules:

.. _cce_10_0296__fig114831750115719:

.. figure:: /_static/images/en-us_image_0000001695737013.png
   :alt: **Figure 1** autoscaler architecture

   **Figure 1** autoscaler architecture

**Description**

-  **Estimator**: Evaluates the number of nodes to be added to each node pool to host unschedulable pods.
-  **Simulator**: Finds the nodes that meet the scale-in conditions in the scale-in scenario.
-  **Expander**: Selects an optimal node from the node pool picked out by the Estimator based on the user-defined policy in the scale-out scenario. Currently, the Expander has the following policies:

   .. table:: **Table 1** **Expander policies supported by CCE**

      +-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
      | Policy          | Description                                                                                                                                                                                                                                        | Application Scenario                                                                                                                                                                                                                                                                             | Example                                                                                                                                                                                                 |
      +=================+====================================================================================================================================================================================================================================================+==================================================================================================================================================================================================================================================================================================+=========================================================================================================================================================================================================+
      | Random          | Randomly selects a schedulable node pool to perform the scale-out.                                                                                                                                                                                 | This policy is typically used as a basic backup for other complex policies. Only use this policy if the other policies cannot be used.                                                                                                                                                           | Assume that auto scaling is enabled for node pools 1 and 2 in the cluster and the scale-out upper limit is not reached. The policy for scaling out the number of replicas for a workload is as follows: |
      |                 |                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                  |                                                                                                                                                                                                         |
      |                 |                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                  | #. Pending pods trigger the autoscaler to determine the scale-out process.                                                                                                                              |
      |                 |                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                  | #. autoscaler simulates the scheduling phase and evaluates that the pending pods can be scheduled to the added nodes in both node pools 1 and 2.                                                        |
      |                 |                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                  | #. autoscaler randomly selects node pool 1 or node pool 2 for scale-out.                                                                                                                                |
      +-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
      | most-pods       | A combined policy. It takes precedence over the random policy.                                                                                                                                                                                     | This policy is based on the maximum number of pods that can be scheduled.                                                                                                                                                                                                                        | Assume that auto scaling is enabled for node pools 1 and 2 in the cluster and the scale-out upper limit is not reached. The policy for scaling out the number of replicas for a workload is as follows: |
      |                 |                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                  |                                                                                                                                                                                                         |
      |                 | Preferentially selects the node pool that can schedule the most pods after scale-out. If multiple node pools meet the condition, the random policy is used for further decision-making.                                                            |                                                                                                                                                                                                                                                                                                  | #. Pending pods trigger the autoscaler to determine the scale-out process.                                                                                                                              |
      |                 |                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                  | #. autoscaler simulates the scheduling phase and evaluates that some pending pods can be scheduled to the added nodes in both node pools 1 and 2.                                                       |
      |                 |                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                  | #. autoscaler evaluates that node pool 1 can schedule 20 new pods and node pool 2 can schedule only 10 new pods after scale-out. Therefore, autoscaler selects node pool 1 for scale-out.               |
      +-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
      | least-waste     | A combined policy. It takes precedence over the random policy.                                                                                                                                                                                     | This policy uses the minimum waste score of CPU or memory resources as the selection criteria.                                                                                                                                                                                                   | Assume that auto scaling is enabled for node pools 1 and 2 in the cluster and the scale-out upper limit is not reached. The policy for scaling out the number of replicas for a workload is as follows: |
      |                 |                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                  |                                                                                                                                                                                                         |
      |                 | autoscaler evaluates the overall CPU or memory allocation rate of the node pools and selects the node pool with the minimum CPU or memory waste. If multiple node pools meet the condition, the random policy is used for further decision-making. | The formula for calculating the minimum waste score (wastedScore) is as follows:                                                                                                                                                                                                                 | #. Pending pods trigger the autoscaler to determine the scale-out process.                                                                                                                              |
      |                 |                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                  | #. autoscaler simulates the scheduling phase and evaluates that some pending pods can be scheduled to the added nodes in both node pools 1 and 2.                                                       |
      |                 |                                                                                                                                                                                                                                                    | -  wastedCPU = (Total number of CPUs of the nodes to be scaled out - Total number of CPUs of the pods to be scheduled)/Total number of CPUs of the nodes to be scaled out                                                                                                                        | #. autoscaler evaluates that the minimum waste score of node pool 1 after scale-out is smaller than that of node pool 2. Therefore, autoscaler selects node pool 1 for scale-out.                       |
      |                 |                                                                                                                                                                                                                                                    | -  wastedMemory = (Total memory size of nodes to be scaled out - Total memory size of pods to be scheduled)/Total memory size of nodes to be scaled out                                                                                                                                          |                                                                                                                                                                                                         |
      |                 |                                                                                                                                                                                                                                                    | -  wastedScore = wastedCPU + wastedMemory                                                                                                                                                                                                                                                        |                                                                                                                                                                                                         |
      +-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
      | priority        | A combined policy. The priorities for the policies are as follows: priority > least-waste > random.                                                                                                                                                | This policy allows you to configure and manage the priorities of node pools or scaling groups through the console or API, while the least-waste policy can reduce the resource waste ratio in common scenarios. This policy has wider applicability and is used as the default selection policy. | Assume that auto scaling is enabled for node pools 1 and 2 in the cluster and the scale-out upper limit is not reached. The policy for scaling out the number of replicas for a workload is as follows: |
      |                 |                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                  |                                                                                                                                                                                                         |
      |                 | It is an enhanced least-waste policy configured based on the node pool or scaling group priority. If multiple node pools meet the condition, the least-waste policy is used for further decision-making.                                           |                                                                                                                                                                                                                                                                                                  | #. Pending pods trigger the autoscaler to determine the scale-out process.                                                                                                                              |
      |                 |                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                  | #. autoscaler simulates the scheduling phase and evaluates that some pending pods can be scheduled to the added nodes in both node pools 1 and 2.                                                       |
      |                 |                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                  | #. autoscaler evaluates that node pool 1 has a higher priority than node pool 2. Therefore, autoscaler selects node pool 1 for scale-out.                                                               |
      +-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
