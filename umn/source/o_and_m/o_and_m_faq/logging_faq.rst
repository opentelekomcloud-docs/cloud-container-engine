:original_name: cce_10_0809.html

.. _cce_10_0809:

Logging FAQ
===========

Indexes
-------

-  :ref:`How Do I Disable Logging? <cce_10_0809__section79501212173811>`
-  :ref:`What Can I Do If All Components Except log-operator Are Not Ready? <cce_10_0809__section4325193116367>`
-  :ref:`How Do I Handle the Error in Stdout Logs of log-operator? <cce_10_0809__section1674113819365>`
-  :ref:`What Can I Do If Container File Logs Cannot Be Collected When Docker Is Used as the Container Engine? <cce_10_0809__section15385204383613>`
-  :ref:`What Can I Do If Container File Logs Cannot Be Collected Due to the Wildcard in the Collection Directory? <cce_10_0809__section011012583364>`
-  :ref:`What Can I Do If fluent-bit Pod Keeps Restarting? <cce_10_0809__section1880322183714>`
-  :ref:`What Can I Do If Job Logs Cannot Be Collected? <cce_10_0809__section97887823715>`
-  :ref:`What Can I Do If the Cloud Native Log Collection Add-on is Running Normally but Some Log Collection Policies Do Not Take Effect? <cce_10_0809__section1571017353814>`
-  :ref:`What Can I Do If Some Pod Information Is Missing During Log Collection Due to Excessive Node Load? <cce_10_0809__section1990316243587>`
-  :ref:`How Do I Change the Log Storage Period on Logging? <cce_10_0809__section1053145216227>`
-  :ref:`What Can I Do If the Log Group or Stream Specified in the Log Collection Policy Does Not Exist? <cce_10_0809__section494412903313>`

.. _cce_10_0809__section79501212173811:

How Do I Disable Logging?
-------------------------

**Disabling container log and Kubernetes event collection**

Method 1: Log in to the CCE console and click the cluster name to access the cluster console. In the navigation pane, choose **Logging**. In the upper right corner, click **View Log Collection Policies**. Then, locate and delete the corresponding log collection policy.

Method 2: Access the **Add-ons** page and uninstall the Cloud Native Log Collection add-on. **Note that after you uninstall this add-on, it will no longer report Kubernetes events to AOM.**

**Disabling log collection for control plane components**

Choose **Logging** > **Control Plane Logs** and deselect one or more components whose logs do not need to be collected.

**Disabling Kubernetes audit log collection**

Choose **Logging** > **Kubernetes Audit Logs** and deselect the component whose logs do not need to be collected.

.. _cce_10_0809__section4325193116367:

What Can I Do If All Components Except log-operator Are Not Ready?
------------------------------------------------------------------

**Symptom**: All components except log-operator are not ready, and the volume failed to be mounted to the node.

**Solution**: Check the logs of log-operator. During add-on installation, the configuration files required by other components are generated by log-operator. If the configuration files are invalid, all components cannot be started.

The log information is as follows:

.. code-block::

   MountVolume.SetUp failed for volume "otel-collector-config-vol":configmap "log-agent-otel-collector-config" not found

.. _cce_10_0809__section1674113819365:

How Do I Handle the Error in Stdout Logs of log-operator?
---------------------------------------------------------

**Symptom**:

.. code-block::

   2023/05/05 12:17:20.799 [E] call 3 times failed, reason: create group failed, projectID: xxx, groupName: k8s-log-xxx, err: create groups status code: 400, response: {"error_code":"LTS.0104","error_msg":"Failed to create log group, the number of log groups exceeds the quota"}, url: https://lts.***.com/v2/xxx/groups, process will retry after 45s

**Solution**: On the LTS console, delete unnecessary log groups.

.. _cce_10_0809__section15385204383613:

What Can I Do If Container File Logs Cannot Be Collected When Docker Is Used as the Container Engine?
-----------------------------------------------------------------------------------------------------

**Symptom**:

A container file path is configured but is not mounted to the container, and Docker is used as the container engine. As a result, logs cannot be collected.

**Solution**:

Check whether Device Mapper is used for the node where the workload resides. Device Mapper does not support text log collection. (This restriction is displayed when you create a log collection policy.) To check this, perform the following operations:

#. Go to the node where the workload resides.
#. Run the **docker info \| grep "Storage Driver"** command.
#. If the value of **Storage Driver** is **Device Mapper**, text logs cannot be collected.

.. _cce_10_0809__section011012583364:

What Can I Do If Container File Logs Cannot Be Collected Due to the Wildcard in the Collection Directory?
---------------------------------------------------------------------------------------------------------

**Troubleshooting**: Check the volume mounting status in the workload configuration. If a volume is attached to the data directory of a service container, this add-on cannot collect data from the parent directory. In this case, you need to set the collection directory to a complete data directory. For example, if the data volume is attached to the **/var/log/service** directory, logs cannot be collected from the **/var/log** or **/var/log/\*** directory. In this case, you need to set the collection directory to **/var/log/service**.

**Solution**: If the log generation directory is **/application/logs/**\ *{Application name}*\ **/*.log**, attach the data volume to the **/application/logs** directory and set the collection directory in the log collection policy to **/application/logs/*/*.log**.

.. _cce_10_0809__section1880322183714:

What Can I Do If fluent-bit Pod Keeps Restarting?
-------------------------------------------------

**Troubleshooting**: Run the **kubectl describe pod** command. The output shows that the pod was restarted due to OOM. There are a large number of evicted pods on the node where the fluent-bit resides. As a result, resources are occupied, causing OOM.

**Solution**: Delete the evicted pods from the node.

.. _cce_10_0809__section97887823715:

What Can I Do If Job Logs Cannot Be Collected?
----------------------------------------------

**Troubleshooting**: Check the job lifetime. If the job lifetime is less than 1 minute, the pod will be destroyed before logs are collected. In this case, logs cannot be collected.

**Solution**: Prolong the job lifetime.

.. _cce_10_0809__section1571017353814:

What Can I Do If the Cloud Native Log Collection Add-on is Running Normally but Some Log Collection Policies Do Not Take Effect?
--------------------------------------------------------------------------------------------------------------------------------

**Solution**:

-  If the log collection policy of the event type does not take effect or the add-on version is earlier than 1.5.0, check the stdout of the log-agent-otel-collector workload.

   Go to the **Add-ons** page and click **Cloud Native Log Collection**. Then, click the **Pods** tab, locate **log-agent-otel-collector**, and choose **More** > **View Log** in the **Operation** column.

-  If the log collection policy of the other type does not take effect and the add-on version is later than 1.5.0, check the log of log-agent-fluent-bit on the node where the container to be monitored is running.

   Go to the **Add-ons** page and click **Cloud Native Log Collection**. Then, click the **Pods** tab, locate **log-agent-fluent-bit**, and choose **More** > **View Log** in the **Operation** column.

   Select the fluent-bit container, search for the keyword "fail to push {event/log} data via lts exporter" in the log, and view the error message.

   #. If the error message "The log streamId does not exist." is displayed, the log group or log stream does not exist. In this case, choose **Logging** > **View Log Collection Policies**, edit or delete the log collection policy, and recreate a log collection policy to update the log group or log stream.
   #. For other errors, go to LTS to search for the error code and view the cause.

.. _cce_10_0809__section1990316243587:

What Can I Do If Some Pod Information Is Missing During Log Collection Due to Excessive Node Load?
--------------------------------------------------------------------------------------------------

When the Cloud Native Log Collection add-on version is later than 1.5.0, some pod information, such as the pod ID and name, is missing from container file logs or stdout logs.

**Troubleshooting**:

Go to the **Add-ons** page and click **Cloud Native Log Collection**. Then, click the **Pods** tab, locate **log-agent-fluent-bit**, and choose **More** > **View Log** in the **Operation** column.

Select the fluent-bit container and search for the keyword "cannot increase buffer: current=512000 requested=**\* max=512000" in the log.

**Solution**:

Run the **kubectl edit deploy -n monitoring log-agent-log-operator** command on the node and add **--kubernetes-buffer-size=20MB** to the command lines of the log-operator container. The default value is **16MB**. You can estimate the value based on the total size of pod information on the node. **0** indicates no limits.

.. caution::

   If the Cloud Native Log Collection add-on is upgraded, you need to reconfigure **kubernetes-buffer-size**.


.. figure:: /_static/images/en-us_image_0000002253619901.png
   :alt: **Figure 1** Modifying the command line parameter of the log-operator container

   **Figure 1** Modifying the command line parameter of the log-operator container

.. _cce_10_0809__section1053145216227:

How Do I Change the Log Storage Period on Logging?
--------------------------------------------------

#. On the **Clusters** page, hover the cursor over the cluster name to view the current cluster ID.
#. Log in to the LTS console. In the navigation pane, choose **Log Management**. In **Log Groups**, select a search criterion. Then, query the log group and log stream by cluster ID.
#. Locate the log group and click **Modify** to configure the log storage period.

.. _cce_10_0809__section494412903313:

What Can I Do If the Log Group or Stream Specified in the Log Collection Policy Does Not Exist?
-----------------------------------------------------------------------------------------------

-  **Scenario 1: The default log group or stream does not exist.**

   Take Kubernetes events as an example. If the default log group or stream does not exist, a message will be displayed on the Kubernetes events page of the console. You can click **Create Log Collection Policy** to create a log group or stream.

   After the log group or stream is created, the ID of the default log group or stream changes, and the existing log collection policy of the default log group or stream does not take effect. In this case, you can rectify the fault by referring to :ref:`Scenario 2 <cce_10_0809__li146683521096>`.

-  .. _cce_10_0809__li146683521096:

   **Scenario 2: The default log group or stream exists but is inconsistent with that specified in the log collection policy.**

   -  The log collection policy, for example, **default-stdout**, can be modified as follows:

      #. Log in to the CCE console and click the cluster name to access the cluster console. In the navigation pane, choose **Logging**.
      #. In the upper right corner, click **View Log Collection Policies**. Then, locate the log collection policy and click **Edit** in the **Operation** column.
      #. Select **Custom** and configure the default log group or stream.

   -  If a log collection policy cannot be modified, for example, **default-event**, you need to re-create a log collection policy as follows:

      #. Log in to the CCE console and click the cluster name to access the cluster console. In the navigation pane, choose **Logging**.
      #. In the upper right corner, click **View Log Collection Policies**. Then, locate the log collection policy and click **Delete** in the **Operation** column.
      #. Click **Create Log Collection Policy**. Then, select **Kubernetes events** and click **OK**.

-  **Scenario 3: The custom log group (stream) does not exist.**

   CCE does not support the creation of non-default log groups (streams). You can create a non-default log group (stream) on the LTS console.

   After the creation is complete, take the following steps:

   #. Log in to the CCE console and click the cluster name to access the cluster console. In the navigation pane, choose **Logging**.
   #. In the upper right corner, click **View Log Collection Policies**. Then, locate the log collection policy and click **Edit** in the **Operation** column.
   #. Select **Custom** and configure a log group or stream.
